{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Primary Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code summary of below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from backend import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = '../texts/fiction/utf8/'\n",
    "\n",
    "libCols = ['author','pub_year','title','text']\n",
    "tokenOHCO = ['w_id','part_num','para_num', 'sent_num', 'token_num']\n",
    "tokenCols = ['p_id', 'start', 'stop', 'text', 'token_id', 'head_id', 'rel', 'pos', 'lemma', 'anim', 'aspect', \\\n",
    "             'case', 'degree', 'gender', 'mood', 'number', 'person', 'tense', 'verb_form', 'voice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!curl --silent https://xkcd.com/color/rgb.txt | grep -E '(\\w+\\s?\\w?\\s?)(#[[:alnum:]]{6})' > xkcd_colors.txt\n",
    "xkcd_colors_list = './xkcd_colors.txt'\n",
    "with open(xkcd_colors_list, 'r') as f: \n",
    "    xkcd_colors = f.readlines()\n",
    "xkcd_colors_dict = {}\n",
    "for color in [x.split('\\t') for x in xkcd_colors]:\n",
    "    xkcd_colors_dict.update({color[0]:color[1]})\n",
    "    \n",
    "def xkcd_color_picker():\n",
    "    color_id = list(xkcd_colors_dict.items())[random.randint(0, len(xkcd_colors_dict)-1)]\n",
    "    return color_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "libDf = pd.DataFrame(columns = libCols)\n",
    "for t in os.listdir(texts): \n",
    "    if t[-4:] == '.txt': \n",
    "        #print(t)\n",
    "        info = re.match(r'(\\w+)-(\\d{4})-(.+).txt', t)\n",
    "        with codecs.open(texts+t, 'r') as f: \n",
    "            textytext = f.read()\n",
    "        subDf = pd.DataFrame({'author': info.group(1),'pub_year': int(info.group(2)), 'title': info.group(3), 'text': textytext}, index=[1])\n",
    "        libDf = pd.concat([libDf, subDf], ignore_index=True)\n",
    "        \n",
    "libDf = libDf.sort_values(libCols[1:3]).reset_index().drop(['index'], axis=1)\n",
    "libDf.index.name = 'w_id'\n",
    "libTextsDf = libDf[[libCols[3]]]\n",
    "libDf = libDf.drop(columns=[libCols[3]])\n",
    "libDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libTextsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confessionTextDf = textRegularize(libTextsDf, 10)\n",
    "confessionTextDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpTextDf = textRegularize(libTextsDf, 14)\n",
    "dpTextDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motherTextDf = textRegularize(libTextsDf, 6)\n",
    "motherTextDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motherTextDf.groupby('chapID').paraID.count().to_frame().plot(kind='bar', ylabel='# paragraphs', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into chapters\n",
    "detstvoTextDf = libTextsDf.loc[[22]]\n",
    "detstvoTextDf = pd.DataFrame(data=detstvoTextDf.text.str.split(r'\\*\\w+\\*\\n\\n').to_list()[0]).reset_index()\n",
    "detstvoTextDf = detstvoTextDf.rename(columns={'index':'chap', 0:'text'})[1:]\n",
    "detstvoTextDf = detstvoTextDf.text.str.split('\\n\\n', expand=True).stack().to_frame().reset_index().drop('level_1', axis=1).drop([1, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22], axis=0)\n",
    "detstvoTextDf = detstvoTextDf.rename(columns={'level_0':'chap', 0:'text'})\n",
    "detstvoTextDf = detstvoTextDf['text'].str.split(' \\n', expand=True).stack().to_frame().reset_index().rename(columns={'level_0':'chapID','level_1':'para',0:'text'})\n",
    "# regularize\n",
    "detstvoTextDf['text'] = detstvoTextDf.text.str.replace('\\n|\\s{2,}', '')\n",
    "# remove white space paragraphs\n",
    "detstvoTextDf = detstvoTextDf.loc[~detstvoTextDf.text.str.contains(r\"^\\W*$\", regex=True)]\n",
    "#textDf['part'] = detstvoTextDf.chapID.apply(lambda x: int('1') if x < 30 else int('2'))\n",
    "#textDf['chap'] = detstvoTextDf.chapID.map(textDf['chapID'].to_dict())\n",
    "detstvoTextDf['para'] = detstvoTextDf['para'].apply(lambda x: x+1)\n",
    "detstvoTextDf['paraID'] = range(1, len(detstvoTextDf)+1)\n",
    "detstvoTextDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "motherTokenDf = nat_parse(motherTextDf.set_index('paraID')[['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motherTokenDf = pd.read_pickle('./proc/MotherTokendf.pkl')#.set_index(['p_id','token_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motherTokenDf.set_index(['p_id','token_id'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def display_side_by_side(dfs:list, captions:list, tablespacing=5):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    for (caption, df) in zip(captions, dfs):\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += tablespacing * \"\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "df1 = motherTokenDf.rel.value_counts().to_frame()\n",
    "df2 = motherTokenDf.anim.value_counts().to_frame()\n",
    "df3 = motherTokenDf.aspect.value_counts().to_frame()\n",
    "df4 = motherTokenDf.case.value_counts().to_frame()\n",
    "df5 = motherTokenDf.degree.value_counts().to_frame()\n",
    "df6 = motherTokenDf.gender.value_counts().to_frame()\n",
    "df7 = motherTokenDf.mood.value_counts().to_frame()\n",
    "df8 = motherTokenDf.number.value_counts().to_frame()\n",
    "df9 = motherTokenDf.person.value_counts().to_frame()\n",
    "df10 = motherTokenDf.tense.value_counts().to_frame()\n",
    "df11 = motherTokenDf.verb_form.value_counts().to_frame()\n",
    "df12 = motherTokenDf.voice.value_counts().to_frame()\n",
    "\n",
    "display_side_by_side([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12], ['rel', 'anim', 'aspect', 'case', 'degree', 'gender', 'mood', 'number', 'person', 'tense', 'verb form', 'voice'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "from ipywidgets import widgets, Layout\n",
    "from IPython import display\n",
    "\n",
    "# sample data\n",
    "df1 = pd.DataFrame(np.random.randn(8, 3))\n",
    "df2 = pd.DataFrame(np.random.randn(8, 3))\n",
    "\n",
    "# create output widgets\n",
    "widget1 = widgets.Output()\n",
    "widget2 = widgets.Output()\n",
    "\n",
    "# render in output widgets\n",
    "with widget1:\n",
    "    display.display(df1.style.set_caption('First dataframe'))\n",
    "    df1.info()\n",
    "with widget2:\n",
    "    display.display(df2.style.set_caption('Second dataframe'))\n",
    "    df1.info()\n",
    "\n",
    "\n",
    "# add some CSS styles to distribute free space\n",
    "box_layout = Layout(display='flex',\n",
    "                    flex_flow='row',\n",
    "                    justify_content='space-around',\n",
    "                    width='auto'\n",
    "                   )\n",
    "    \n",
    "# create Horisontal Box container\n",
    "hbox = widgets.HBox([widget1, widget2], layout=box_layout)\n",
    "\n",
    "# render hbox\n",
    "hbox"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "confessionTokenDf = nat_parse(confessionTextDf.set_index('paraID')[['text']])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "confessionTokenDf.to_pickle('./proc/ConfessionTokenDf.pkl')#.set_index(['p_id', 'token_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confessionTokenDf = pd.read_pickle('./proc/ConfessionTokenDf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confessionTokenDf.set_index(['p_id', 'token_id'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "detstvoTokenDf = nat_parse(detstvoTextDf.set_index('paraID')[['text']])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "detstvoTokenDf.to_pickle('./proc/ChildhoodTokenDf.pkl')#.set_index(['p_id', 'token_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "childhoodTokenDf = pd.read_pickle('./proc/ChildhoodTokenDf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "childhoodTokenDf.set_index(['p_id', 'token_id'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "dpTokenDf = nat_parse(dpTextDf.set_index('paraID')[['text']])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "dpTokenDf.to_pickle('./proc/DpTokenDf.pkl')#.set_index(['p_id', 'token_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dpTokenDf = pd.read_pickle('./proc/DpTokenDf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dpTokenDf.set_index(['p_id', 'token_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motherRankDf = GetRankDf(motherTokenDf)\n",
    "motherRankDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confessionRankDf = GetRankDf(confessionTokenDf)\n",
    "confessionRankDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "childhoodRankDf = GetRankDf(childhoodTokenDf)\n",
    "childhoodRankDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dpRankDf = GetRankDf(dpTokenDf)\n",
    "dpRankDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrangeFigures(*figures):\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    sns.plotType(someData, ax=ax[0])  # plot1\n",
    "    sns.plotType(someData, ax=ax[1])  # plot2\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Token Matrices (TTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def makeBOW(tokenDf):\n",
    "    bowDf = tokenDf.groupby(['p_id', 'lemma']).lemma.count().to_frame('n')\n",
    "    return bowDf\n",
    "\n",
    "def makeDTCM(bowDf):\n",
    "    dtcmDf = bowDf.n.unstack(fill_value=0)\n",
    "    return dtcmDf\n",
    "\n",
    "def makeTTM(tokenDf):\n",
    "    TTM = pd.get_dummies(tokenDf['lemma'], columns=['lemma'], prefix_sep='', drop_first=False).reset_index(drop=True).iloc[:,1:]\n",
    "    TTM.index.name = 'time_id'\n",
    "    TTM = TTM.astype('int')\n",
    "    return TTM\n",
    "\n",
    "def getVocabTTM(TTM, vocab_words):\n",
    "    cfg = {'figsize': (20,6)}\n",
    "    num_words = len(vocab_words)\n",
    "    fig, axs = plt.subplots(num_words, sharex=True, sharey=True, **cfg)\n",
    "    fig.suptitle('Appearance of vocab in Mother')\n",
    "    for i in range(0, num_words):\n",
    "        graph_color = xkcd_color_picker()[1]\n",
    "        axs[i].plot(TTM[vocab_words[i]], graph_color)\n",
    "        axs[i].set_title(vocab_words[i], color=graph_color, rotation='vertical',x=-0.01,y=0.3)\n",
    "    for ax in axs:\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ttmwords = ['мать', 'павел', 'христос']\n",
    "motherTTM = makeTTM(motherTokenDf)\n",
    "getVocabTTM(motherTTM, ttmwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motherRankDf, confessionRankDf, childhoodRankDf, dpRankDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motherChapParaDict = dict(zip(motherTextDf.paraID, motherTextDf.chapID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motherTokenDf = motherTokenDf.reset_index().drop('index', axis=1)\n",
    "motherTokenDf['c_id'] = motherTokenDf.p_id.apply(lambda x: motherChapParaDict.get(x))\n",
    "motherTokenDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motherBOW = motherTokenDf.groupby(['c_id', 'lemma']).lemma.count().to_frame('n')\n",
    "motherDTCM = motherBOW.n.unstack(fill_value=0)\n",
    "\n",
    "motherTF = motherDTCM.T / motherDTCM.T.sum()\n",
    "motherTF = motherTF.transpose()\n",
    "\n",
    "motherDF = motherDTCM.astype('bool').sum()\n",
    "motherN = motherDTCM.shape[0]\n",
    "motherIDF = np.log2(motherN / motherDF)\n",
    "\n",
    "motherTFIDF = motherTF * motherIDF\n",
    "\n",
    "motherRankDf['df'] = motherDF\n",
    "motherRankDf['idf'] = motherIDF\n",
    "\n",
    "motherBOW['tf'] = motherTF.stack()\n",
    "motherBOW['tfidf'] = motherTFIDF.stack()\n",
    "motherBOW.sort_values('tfidf', ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motherDTCM = motherBOW.n.unstack(fill_value=0)\n",
    "MothermotherTF = motherDTCM.T / motherDTCM.T.sum()\n",
    "motherTF = motherTF.transpose()\n",
    "motherDF = motherDTCM.astype('bool').sum()\n",
    "motherN = motherDTCM.shape[0]\n",
    "motherIDF = np.log2(motherN / motherDF)\n",
    "motherTFIDF = motherTF * motherIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motherRankDf['df'] = motherDF\n",
    "motherRankDf['idf'] = motherIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motherRankDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motherBOW['tf'] = motherTF.stack()\n",
    "motherBOW['tfidf'] = motherTFIDF.stack()\n",
    "motherBOW.sort_values('tfidf', ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IDF = makeDTCM(makeBOW(childhoodTokenDf)).astype('bool').sum()\n",
    "TF = makeBOW(childhoodTokenDf).groupby('p_id').apply(lambda x: x.n / x.n.sum())\n",
    "TFIDF = TF * IDF\n",
    "TFIDF = TFIDF.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vector Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fasttext_model_loc = './models/cc.ru.300.bin'\n",
    "ft = fasttext.load_model(fasttext_model_loc)\n",
    "ft.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motherModel = fasttext.train_unsupervised('./models/gorkii-1906-mother.txt', model='skipgram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import plotly_express as px\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "libDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motherTokenDf['w_id'] = 6\n",
    "confessionTokenDf['w_id'] = 10\n",
    "tokensDf = pd.concat([confessionTokenDf, motherTokenDf]).set_index('w_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokensDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "pca_engine = PCA(n_components=10)\n",
    "\n",
    "DCM = pd.DataFrame(pca_engine.fit_transform(TFIDF.fillna(0)), index=TFIDF.index)\n",
    "DCM.columns = ['PC{}'.format(i) for i in DCM.columns]\n",
    "DCM = DCM.join(LIB[['author','label']], on='book_id')\n",
    "\n",
    "def vis_pcs(M, a, b, label='author', hover_name='label', symbol=None, size=None):\n",
    "    return px.scatter(M, f\"PC{a}\", f\"PC{b}\", color=label, hover_name=hover_name, \n",
    "                     symbol=symbol, size=size,\n",
    "                     marginal_x='box', height=800)\n",
    "\n",
    "def vis_loadings(a=0, b=1, hover_name='term_str'):\n",
    "    X = LOADINGS.join(VSHORT)\n",
    "    return px.scatter(X.reset_index(), f\"PC{a}\", f\"PC{b}\", \n",
    "                      text='term_str', size='i', color='max_pos_group', \n",
    "                      marginal_x='box', height=800)\n",
    "\n",
    "vis_pcs(DCM, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_engine = PCA(n_components=10)\n",
    "\n",
    "DCM = pd.DataFrame(pca_engine.fit_transform(TFIDF.fillna(0)), index=TFIDF.index)\n",
    "DCM.columns = ['PC{}'.format(i) for i in DCM.columns]\n",
    "DCM = DCM.join(LIB[['author','label']], on='book_id')\n",
    "\n",
    "def vis_pcs(M, a, b, label='author', hover_name='label', symbol=None, size=None):\n",
    "    return px.scatter(M, f\"PC{a}\", f\"PC{b}\", color=label, hover_name=hover_name, \n",
    "                     symbol=symbol, size=size,\n",
    "                     marginal_x='box', height=800)\n",
    "\n",
    "def vis_loadings(a=0, b=1, hover_name='term_str'):\n",
    "    X = LOADINGS.join(VSHORT)\n",
    "    return px.scatter(X.reset_index(), f\"PC{a}\", f\"PC{b}\", \n",
    "                      text='term_str', size='i', color='max_pos_group', \n",
    "                      marginal_x='box', height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "\n",
    "navec_model_loc = './models/navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
    "navec = Navec.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from slovnet.model.emb import NavecEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = NavecEmbedding(navec)\n",
    "input = torch.tensor([1, 2, 0])\n",
    "output = emb(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, embeddings):\n",
    "    # Simple tokenization based on spaces (for demonstration purposes)\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Initialize an empty tensor for storing embeddings\n",
    "    vector = torch.zeros(embeddings.dim)\n",
    "    \n",
    "    for token in tokens:\n",
    "        # Add the embeddings of each token; you might want to handle OOV (out-of-vocabulary) tokens\n",
    "        vector += embeddings.get_vecs_by_tokens(token.lower(), lower_case_backup=True)\n",
    "    \n",
    "    # Average the vectors (simple approach)\n",
    "    return vector / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'text': ['Hello world', 'PyTorch vectorization example', 'Text vectorization with PyTorch']}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading GloVe embeddings\n",
    "glove = GloVe(name='6B', dim=100)  # Example: 100-dimensional GloVe vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply vectorization to each row in the DataFrame\n",
    "df['vector'] = df['text'].apply(lambda x: vectorize_text(x, glove))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss",
   "language": "python",
   "name": "diss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
