{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa07089e",
   "metadata": {},
   "source": [
    "# Russian Synodal Bible (1885)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db1fea7",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e48e5b",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af782c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#from lxml import etree\n",
    "from backend import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b45fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "names_extractor = NamesExtractor(morph_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afadbec5",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a42e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bibleTXT = './texts/bible/sinodalnyi-perevod.txt' \n",
    "booksJSON = './texts/bible/booksDict.json'\n",
    "bibleJSON = './texts/bible/bible.json'\n",
    "bibleIdJSON = './texts/bible/bibleID.json'\n",
    "bibleXML = './texts/bible/bible.xml'\n",
    "bibFrazyTXT = './texts/bible/Dubrovina_Slovar_Bibleyskikh_Frazeologizmov.txt'\n",
    "\n",
    "bibleOHCO = ['test', 'book', 'chap', 'verse']\n",
    "tokenCols = ['p_id', 'start', 'stop', 'text', 'token_id', 'head_id', 'rel', 'pos', 'lemma', 'anim', 'aspect', 'case', 'degree', 'gender', 'mood', 'number', 'person', 'tense', 'verb_form', 'voice']\n",
    "\n",
    "chap_lines_re = '^===\\s(\\d{1,3})\\s===$'\n",
    "book_lines_re = '^==\\s(.+)\\s==$'\n",
    "matt_name = 'От Матфея святое благовествование'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e140359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(booksJSON) as json_file: \n",
    "    booksDict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f975d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f2e781",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Text into DF"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72f02826",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "with open(bibleTXT, 'r', encoding='windows-1251') as f: \n",
    "    bibleText = f.readlines()\n",
    "\n",
    "bibliiaDf = pd.DataFrame(bibleText).rename(columns={0:'text'}).dropna()\n",
    "bibliiaDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eae545",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tidy Up"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04cb693d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# remove blank lines and select puncutation, keeping only header & clean text lines\n",
    "bibliiaDf.loc[:,'text'] = bibliiaDf.loc[:,'text'].str.replace(r'\\n', '')\n",
    "bibliiaDf.loc[:,'text'] = bibliiaDf.loc[:,'text'].str.replace('\\]|\\[|_|-|', '')\n",
    "bibliiaDf = bibliiaDf.loc[bibliiaDf.text != '']\n",
    "bibliiaDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8476b8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Find Parts"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70a1d42b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# find df rows containing all the book and chapter title lines \n",
    "# as well as the OT/NT split on the 1st page of Matthew\n",
    "chap_lines = bibliiaDf.loc[bibliiaDf.text.str.contains(chap_lines_re)].index\n",
    "book_lines = bibliiaDf.loc[bibliiaDf.text.str.contains(book_lines_re)].index\n",
    "test_line = bibliiaDf.loc[bibliiaDf.text.str.contains(matt_name)].index\n",
    "\n",
    "# combine the title lines for extraction later\n",
    "title_lines = test_line.append([chap_lines, book_lines]).sort_values()\n",
    "title_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba77b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Assign OHCO Labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7c1bcdb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# ['test']\n",
    "bibliiaDf[bibleOHCO[0]] = np.where(bibliiaDf.index<test_line[0], 'O', 'N')\n",
    "# ['book']\n",
    "bibliiaDf[bibleOHCO[1]] = bibliiaDf.loc[book_lines].text.str.extract(book_lines_re)\n",
    "# ['chap']\n",
    "bibliiaDf[bibleOHCO[2]] = bibliiaDf.loc[chap_lines].text.str.extract(chap_lines_re)\n",
    "# ['verse'] by splitting verse num at beginning from text in current verse lines\n",
    "bibliiaDf[[bibleOHCO[3],'text']] = bibliiaDf.text.str.split(' ', 1, expand=True).iloc[:, [0, 1]]\n",
    "# fill in book and chapter titles to cells below them\n",
    "bibliiaDf[bibleOHCO[1:3]] = bibliiaDf[['book','chap']].ffill()\n",
    "# drop title lines and reset index to give verse id num \n",
    "bibliiaDf = bibliiaDf.drop(title_lines, axis=0).reset_index()#.set_index(bibleOHCO)\n",
    "bibliiaDf.index = range(1,len(bibliiaDf)+1)\n",
    "bibliiaDf.index.name = 'v_id'\n",
    "# reorder columns\n",
    "bibliiaDf = bibliiaDf[['test', 'book', 'chap', 'verse', 'text']]\n",
    "bibliiaDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7cc95",
   "metadata": {},
   "source": [
    "### Swap Full Book Name for Abbreviation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6be8e100",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "book_nums = [(x+1,y) for x,y in enumerate(bibliiaDf.book.unique())]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8aed9ef0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "bibliiaDf.book = [booksDict[str(x)]['eng_abbr'] for x,y in book_nums for name in bibliiaDf.book if y == name]\n",
    "bibliiaDf.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d1dd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Export to JSON"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf68e609",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "bibliiaDf.to_json(bibleJSON, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d18f8",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f54c504-67eb-4e96-9659-cec2640a4dc3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "bibliiaDf = pd.read_json(bibleJSON, orient='index')\n",
    "bibliiaDf.index.name = 'v_id'\n",
    "#BibTextDf = bibliiaDf[['text']]\n",
    "#BibLibDf = bibliiaDf[bibleOHCO]\n",
    "bibliiaDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5f423",
   "metadata": {},
   "source": [
    "### OHCO DFs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f5bcaa4-9ab0-41d2-bf3b-857d578a726e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#testsDict = dict(enumerate(bibliiaDf.test.unique()))\n",
    "testsDict = dict([(value, key) for key, value in dict(enumerate(bibliiaDf.test.unique())).items()])\n",
    "booksDict = dict([(value, key) for key, value in dict(enumerate(bibliiaDf.book.unique())).items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d571e0cf",
   "metadata": {},
   "source": [
    "#### Testaments"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63268275-656a-4af5-9bf2-fa04642eb375",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "TestsDf = pd.DataFrame([(x, ' '.join(y)) for (x,y) in bibliiaDf.groupby(bibleOHCO[:1]).text], columns=['test', 'text']).set_index(np.arange(1,len(bibliiaDf.test.unique())+1))\n",
    "TestsDf.index.name = 't_id'\n",
    "#TestsDf "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b338edc-2bba-4e0f-a852-d1eb12530f01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "bibliiaDf['t_id'] = bibliiaDf.test.map(testsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e809400",
   "metadata": {},
   "source": [
    "#### Books"
   ]
  },
  {
   "cell_type": "raw",
   "id": "184313bf-450a-435e-a826-091cbbfcafc7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "BooksDf = pd.DataFrame([(x, ' '.join(y)) for (x,y) in bibliiaDf.groupby(bibleOHCO[:2]).text], columns=[('test', 'book'), 'text'])\n",
    "BooksDf[['test','book']] = pd.DataFrame(list(BooksDf[('test', 'book')]), index=BooksDf.index, columns=bibleOHCO[:2])\n",
    "del BooksDf[('test', 'book')]\n",
    "BooksDf = BooksDf.replace({\"test\": testsDict, \"book\": booksDict}).sort_values(by=bibleOHCO[:2], ascending=[True, True])\n",
    "BooksDf = BooksDf.reset_index().drop(['index'], axis=1).set_index(np.arange(1,len(bibliiaDf.book.unique())+1))\n",
    "BooksDf.index.name = 'b_id'\n",
    "BooksDf = BooksDf.replace({\"test\":dict(enumerate(bibliiaDf.test.unique())), \"book\":dict(enumerate(bibliiaDf.book.unique()))})\n",
    "#BooksDf = BooksDf.reset_index().set_index(bibleOHCO[:2])\n",
    "#BooksDf "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2751b88d-e578-4cfd-afec-4212b08de915",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "bibliiaDf['b_id'] = bibliiaDf.book.map(BooksDf.reset_index().set_index('book')['b_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0912b9",
   "metadata": {},
   "source": [
    "#### Chapters"
   ]
  },
  {
   "cell_type": "raw",
   "id": "235f1d39-f7c1-497f-945b-fcddc55c5e95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "ChapsDf = pd.DataFrame([(x, ' '.join(y)) for (x,y) in bibliiaDf.groupby(bibleOHCO[:3]).text], columns=[('test', 'book', 'chap'), 'text'])\n",
    "ChapsDf[['test','book','chap']] = pd.DataFrame(list(ChapsDf[('test', 'book', 'chap')]), index=ChapsDf.index, columns=bibleOHCO[:3])\n",
    "del ChapsDf[('test', 'book', 'chap')]\n",
    "ChapsDf = ChapsDf.replace({\"test\": testsDict, \"book\": booksDict}).sort_values(by=bibleOHCO[:3], ascending=[True, True, True])\n",
    "ChapsDf = ChapsDf.reset_index().drop(['index'], axis=1).set_index(np.arange(1,len(ChapsDf)+1))\n",
    "ChapsDf.index.name = 'c_id'\n",
    "ChapsDf = ChapsDf.replace({\"test\":dict(enumerate(bibliiaDf.test.unique())), \"book\":dict(enumerate(bibliiaDf.book.unique()))})\n",
    "#ChapsDf = ChapsDf.reset_index().set_index(bibleOHCO[:3])\n",
    "#ChapsDf"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c0c1a7f-528f-4d5e-bb44-a16511f621c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "bibliiaDf = pd.merge(bibliiaDf, ChapsDf.reset_index()[['book', 'chap', 'c_id']], on=['book', 'chap'], how='inner')\n",
    "bibliiaDf['v_id'] = bibliiaDf.index.to_series().apply(lambda x: x+1)\n",
    "bibliiaDf = bibliiaDf.set_index('v_id')[['t_id', 'b_id', 'c_id', 'text', 'test', 'book', 'chap']]\n",
    "bibliiaDf"
   ]
  },
  {
   "cell_type": "raw",
   "id": "886ddd72-65b0-4742-8847-ca8abed10d8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "bibliiaDf.loc[(bibliiaDf.test == 'O') & (bibliiaDf.book == 'Gen') & (bibliiaDf.chap == 25)]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "979ab688-8e92-437e-9224-3a6887b9a5d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "bibliiaDf.to_json(bibleIdJSON, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090af10f",
   "metadata": {},
   "source": [
    "### Make XML"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b69cd7a0-9d1e-43b2-bd64-8c3e92d6f709",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "bibliiaDf = pd.read_json(bibleIdJSON, orient='index')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "059aa143-97d2-4e24-8237-ad52f1ac9c45",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "root = etree.Element(\"bible\")\n",
    "print(root.tag)\n",
    "t = b = c = v= 1\n",
    "TestList = [x for x in bibliiaDf.test.unique()]\n",
    "for test in range(len(TestList)): \n",
    "    root.append(etree.Element(\"t\", n=str(t), name=TestList[test]))\n",
    "    BookList = list(bibliiaDf.loc[bibliiaDf.test == TestList[test]].book.unique())\n",
    "    for book in range(len(BookList)): \n",
    "        root[test].append(etree.Element(\"b\", n=str(b), name=BookList[book]))\n",
    "        ChapList = list(bibliiaDf.loc[bibliiaDf.book == BookList[book]].chap.unique())\n",
    "        for chap in range(len(ChapList)): \n",
    "            root[test][book].append(etree.Element(\"c\", n=str(c), name=str(chap+1)))\n",
    "            VerseList = list(bibliiaDf.loc[(bibliiaDf.test == TestList[test]) & (bibliiaDf.book == BookList[book]) & (bibliiaDf.chap == (chap+1))].index)\n",
    "            for verse in range(len(VerseList)): \n",
    "                root[test][book][chap].append(etree.Element(\"v\", n=str(v), name=str(verse+1)))\n",
    "                root[test][book][chap][verse].text = bibliiaDf.loc[v].text\n",
    "                v+=1\n",
    "            c+=1\n",
    "        b+=1\n",
    "    t+=1\n",
    "#print(etree.tostring(root, pretty_print=True, xml_declaration=True))\n",
    "etree.ElementTree(root).write(bibleXML, pretty_print=True, xml_declaration=True, encoding='windows-1251')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bca5a-c656-416c-a340-c39f6a9c237f",
   "metadata": {},
   "source": [
    "## Token DFs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2f6c735-64f5-43b2-93f8-2816b2ad08eb",
   "metadata": {},
   "source": [
    "%%time\n",
    "ChapsTokenDf = nat_parse(ChapsDf)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8d237e2-dd83-4928-b583-046acda27150",
   "metadata": {},
   "source": [
    "%%time\n",
    "VerseTokenDf = nat_parse(BibTextDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TokenDf = pd.read_pickle('./proc/BibleVerseTokenDf.pkl')#.set_index(['p_id', 'token_id'])\n",
    "TokenDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRankDf(sourceDf, col='lemma', stop=False): \n",
    "    if stop: \n",
    "        sourceDf = TokenDf.loc[~TokenDf[tokenCols[9:]].isna().all(1)]\n",
    "    RankDf = sourceDf[col].value_counts().to_frame().rename(columns={col:'n'})\n",
    "    RankDf.index.name = col\n",
    "    RankDf['rank'] = np.arange(1,len(RankDf)+1)\n",
    "    return RankDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e473dd-1004-4f6f-a54b-bf6268702973",
   "metadata": {},
   "outputs": [],
   "source": [
    "GetRankDf('lemma', stop=True)[:50].plot(x='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b06b4f-9b73-49f3-9cca-2d3315a45bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "GetRankDf('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76cfdb-50c9-4eec-93af-463ba2b087fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GetRankDf('rel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215acd4-0833-4afe-a7c3-431e56d1b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GetRankDf('anim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d353255-0416-4f81-be7c-6ea4ee2551f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VocabDf.iloc[:50].plot(x='rank');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8bbd1-1007-4566-b30b-3a1621892769",
   "metadata": {},
   "source": [
    "## Bible Phrase Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147eb18-47bd-4379-b7ab-33e33090c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bibFrazyTXT) as bibleFrazy: \n",
    "    bibleFrazyLines = bibleFrazy.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2b903-c7ea-4ef9-8065-8dc55851b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BibleFrazyDf = pd.DataFrame(bibleFrazyLines).rename(columns={0:'fraza'})\n",
    "BibleFrazyDf.loc[:,'fraza'] = BibleFrazyDf.loc[:,'fraza'].apply(lambda x: x.strip().strip('\\n'))\n",
    "BibleFrazyDf = BibleFrazyDf.loc[BibleFrazyDf.fraza != '']\n",
    "BibleFrazyDf.loc[112:30185]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffb14b-cb9a-46c7-8d0d-531ef25cafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BibleFrazyDf.loc[30189:].fraza.to_list()301853018530185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737fc6d-24cb-418c-acbe-1ef118596867",
   "metadata": {},
   "outputs": [],
   "source": [
    "BibleFrazyDf.loc[34064].fraza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb94f6-a8aa-4b2e-b8cf-6c2c5637aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BibleFrazyDf.loc[33944:].fraza.loc[BibleFrazyDf.fraza.str.match('^[а-я]', case=True)].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df9c3a-273f-43aa-b427-6bcd4eb432bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BibleFrazyDf.loc[33944:].fraza.loc[BibleFrazyDf.fraza.str.match('^\\s')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f4e2f-e23e-4c02-98d2-d094f3248d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "FrazyAbbrsDf = BibleFrazyDf.iloc[:105].fraza.str.split(' – ', expand=True).rename(columns={0:\"abbr\", 1:\"fraza\"})\n",
    "FrazyAbbrsDf.loc[:,'abbr'] = FrazyAbbrsDf.loc[:,'abbr'].apply(lambda x: x.strip())\n",
    "FrazyAbbrsDf.loc[:,'fraza'] = FrazyAbbrsDf.loc[:,'fraza'].apply(lambda x: x.strip())\n",
    "FrazyAbbrsDict = FrazyAbbrsDf.set_index('abbr').to_dict().get('fraza')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2837ee73",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# function for applying all of natasha's morphological tagger components to tokens to make a TokenDf\n",
    "def nat_parse(textDf=BibTextDf, textCol='text', columns=tokenCols): \n",
    "    # initialize token dataframe\n",
    "    tokenDf = pd.DataFrame(columns=columns)\n",
    "    # gather row list\n",
    "    for an_id in textDf.index: \n",
    "        pDict = []\n",
    "        doc = Doc(textDf.loc[an_id][textCol])\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "        for token in doc.tokens: \n",
    "            token.lemmatize(morph_vocab)\n",
    "        doc.parse_syntax(syntax_parser)\n",
    "        doc.tag_ner(ner_tagger)\n",
    "        #for sent in enumerate(doc.sents): \n",
    "        #sent_num = sent[0]\n",
    "        #sent_text = sent[1]\n",
    "        for token in [x for x in doc.tokens if x.pos != 'PUNCT']: \n",
    "            #token_num = token[0]\n",
    "            #token_text = token[1]\n",
    "            start = token.start\n",
    "            stop = token.stop\n",
    "            text = token.text\n",
    "            token_id = token.id\n",
    "            head_id = token.head_id\n",
    "            rel = token.rel\n",
    "            pos = token.pos\n",
    "            lemma = token.lemma\n",
    "            # Animacy, Aspect, Case, Degree, Gender, Mood, Number, Person, Tense, VerbForm, Voice\n",
    "            try: \n",
    "                anim = token.feats['Animacy']\n",
    "            except: \n",
    "                anim = None\n",
    "            try: \n",
    "                aspect = token.feats['Aspect']\n",
    "            except: \n",
    "                aspect = None\n",
    "            try: \n",
    "                case = token.feats['Case']\n",
    "            except: \n",
    "                case = None\n",
    "            try: \n",
    "                degree = token.feats['Degree']\n",
    "            except: \n",
    "                degree = None\n",
    "            try: \n",
    "                gender = token.feats['Gender']\n",
    "            except: \n",
    "                gender = None\n",
    "            try: \n",
    "                mood = token.feats['Mood']\n",
    "            except: \n",
    "                mood = None\n",
    "            try: \n",
    "                number = token.feats['Number']\n",
    "            except: \n",
    "                number = None\n",
    "            try: \n",
    "                person = token.feats['Person']\n",
    "            except: \n",
    "                person = None\n",
    "            try: \n",
    "                tense = token.feats['Tense']\n",
    "            except: \n",
    "                tense = None\n",
    "            try: \n",
    "                verb_form = token.feats['VerbForm']\n",
    "            except: \n",
    "                verb_form = None\n",
    "            try: \n",
    "                voice = token.feats['Voice']\n",
    "            except: \n",
    "                voice = None\n",
    "            #print(token)\n",
    "            tokenDict = {\n",
    "                'p_id': an_id,\n",
    "                #'token_num': token_num, \n",
    "                'start': start, \n",
    "                'stop': stop, \n",
    "                'text': text, \n",
    "                'token_id': token_id, \n",
    "                'head_id': head_id, \n",
    "                'rel': rel, \n",
    "                'pos': pos, \n",
    "                'lemma': lemma, \n",
    "                'anim': anim, \n",
    "                'aspect': aspect, \n",
    "                'case': case, \n",
    "                'degree': degree, \n",
    "                'gender': gender, \n",
    "                'mood': mood, \n",
    "                'number': number, \n",
    "                'person': person, \n",
    "                'tense': tense, \n",
    "                'verb_form': verb_form, \n",
    "                'voice': voice\n",
    "            }\n",
    "            pDict.append(tokenDict)\n",
    "            #print(sent)\n",
    "            pDf = pd.DataFrame(pDict, columns=columns)\n",
    "        tokenDf = pd.concat([tokenDf, pDf])\n",
    "    return tokenDf"
   ]
  },
  {
   "cell_type": "raw",
   "id": "954df7a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "%%time\n",
    "with requests.get(\"https://ru.wikipedia.org/wiki/Книги_Библии\") as r: \n",
    "    if r.status_code == 200: \n",
    "        s = BeautifulSoup(r.content, 'html.parser')\n",
    "    else: \n",
    "        print(r.status_code)\n",
    "\n",
    "n=0\n",
    "booksDict = {}\n",
    "\n",
    "for book_row in s.find_all('table')[1].find_all('tr')[2:]: \n",
    "    try: \n",
    "        bookDict = {\n",
    "            \"rus_name\": book_row.find('td').text,\n",
    "            #\"lat_name\": book_row.find_all('td')[1].text,\n",
    "            \"eng_name\": book_row.find_all('td')[2].text,\n",
    "            #\"gre_name\": book_row.find_all('td')[3].text,\n",
    "            \"rus_abbr\": re.search(r'\\w+', book_row.find_all('td')[4].text).group(),\n",
    "            \"eng_abbr\": book_row.find_all('td')[5].text\n",
    "        }\n",
    "        booksDict.update({n: bookDict})\n",
    "        n+=1\n",
    "    except: \n",
    "        pass\n",
    "\n",
    "for book_row in s.find_all('table')[2].find_all('tr')[2:]: \n",
    "    if book_row.find('td').find('a').text != 'Четвёртая книга Маккавейская':\n",
    "        bookDict = {\n",
    "            \"rus_name\": book_row.find('td').find('a').text,\n",
    "            #\"lat_name\": book_row.find_all('td')[3].text,\n",
    "            \"eng_name\": book_row.find_all('td')[4].text.replace('\\n','')\n",
    "        }\n",
    "        booksDict.update({n: bookDict})\n",
    "        n+=1\n",
    "        \n",
    "for book_row in s.find_all('table')[3].find_all('tr')[2:]: \n",
    "    bookDict = {\n",
    "        \"rus_name\": book_row.find('td').find('a').text,\n",
    "        #\"lat_name\": book_row.find_all('td')[3].text,\n",
    "        \"eng_name\": book_row.find_all('td')[4].text.replace('\\n',''),\n",
    "        #print(f\"rus_abbr: {book_row.find_all('td')[5].text}\"),\n",
    "        #print(f\"eng_abbr: {book_row.find_all('td')[6].text}\"),\n",
    "        \"rus_abbr\": re.search(r'^\\d?\\s?\\w+', book_row.find_all('td')[5].text).group(),\n",
    "        \"eng_abbr\": re.search(r'^\\d?\\s?\\w+', book_row.find_all('td')[6].text).group()\n",
    "    }\n",
    "    booksDict.update({n: bookDict})\n",
    "    n+=1\n",
    "print(booksDict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
